{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !!! Make sure to use pytorch-2.3.1 kernel !!!\n",
    "\n",
    "# Only need to run this once. May need to restart kernel after first run!\n",
    "!pip install --user energyflow seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import energyflow as ef\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# For Typing\n",
    "from numpy import ndarray as Array\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sb.set_theme(context=\"notebook\", style=\"whitegrid\", font_scale=1.5, rc={\"figure.figsize\": (9, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We will load in and use a dataset of quark and gluon jets generated by Pythia.\n",
    "\n",
    "This dataset comes from the EnergyFlow authors, big thanks to them! \\\n",
    "https://energyflow.network/ \\\n",
    "https://arxiv.org/abs/1810.05165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "Jets will each be loaded as a list of constituents, storing  $(p_T, \\eta, \\phi, \\texttt{PID})$ for each constituent.\n",
    "\n",
    "From the dataset description:\n",
    ">Each dataset consists of two components:\n",
    ">\n",
    ">X : a three-dimensional numpy array of the jets with shape (num_data,max_num_particles,4).\\\n",
    ">y : a numpy array of quark/gluon jet labels (quark=1 and gluon=0).\n",
    "\n",
    "This will be a **Set Classification Problem**. Mapping a set of objects to a single label for the entire set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = ef.qg_jets.load(cache_dir=\"/global/cfs/cdirs/ntrain1/attention/energyflow/\")\n",
    "\n",
    "num_events, max_constituents, num_basic_features = X.shape\n",
    "\n",
    "print(\"Number of events   : \", num_events)\n",
    "print(\"Max constituents   : \", max_constituents)\n",
    "print(\"Number of basic features : \", num_basic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform a simple train-test split for example purposes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Split the data into the kinematics and pid parts.\n",
    "\n",
    "1. Constituents are stored as padded arrays with maximum length. Use PID to determine masking vector.\n",
    "2. Normalize kinematics to make it easier to learn\n",
    "3. Convert PIDs into one-hot vectors.\n",
    "4. Append the two back together to form the final dataset.\n",
    "\n",
    "This function will also convert from the numpy arrays into torch tensors, which will make it easier to feed into neural networks later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PreprocessingData(NamedTuple):\n",
    "    normalizer: StandardScaler\n",
    "    one_hot_encoder: OneHotEncoder\n",
    "    \n",
    "def preprocess_data(X: Array, y: Array, preprocessing_data: Optional[PreprocessingData] = None) -> Tuple[Array, PreprocessingData]:\n",
    "    pt, rapidity, phi, pid = np.split(X, 4, axis=-1)\n",
    "    pid = pid.astype(np.int64)\n",
    "\n",
    "    # Averege Jet kinematics\n",
    "    total_pt = np.sum(pt, axis=1, keepdims=True)\n",
    "    average_rapidity = np.average(rapidity, weights=pt, axis=1, keepdims=True)\n",
    "    average_phi = np.average(phi, weights=pt, axis=1, keepdims=True)\n",
    "\n",
    "    # Shift features to be centered around the average jet kinematics\n",
    "    pt = pt / total_pt\n",
    "    rapidity = rapidity - average_rapidity\n",
    "    phi = phi - average_phi\n",
    "\n",
    "    # Split phi into sin and cos components.\n",
    "    sin_phi, cos_phi = np.sin(phi), np.cos(phi)\n",
    "\n",
    "    # Combine features into a single array.\n",
    "    X_kinematics = np.concatenate([pt, rapidity, sin_phi, cos_phi], axis=-1)\n",
    "    X_pid = pid[..., 0]\n",
    "\n",
    "    # Sort kinematics by PT.\n",
    "    # This doesnt change training, but makes it easier to visualize the data later.\n",
    "    sorting_indices = np.argsort(X_kinematics[..., 0], axis=1)\n",
    "    sorting_indices = np.flip(sorting_indices, axis=1)  \n",
    "    X_kinematics = X_kinematics[np.arange(len(X_kinematics))[:, None], sorting_indices]\n",
    "    X_pid = X_pid[np.arange(len(X_kinematics))[:, None], sorting_indices]\n",
    "    \n",
    "    # Convert targets into binary boolean values.\n",
    "    y = y > 0.5\n",
    "\n",
    "    # Determine mask from PID. This mask is a NEGATIVE mask.\n",
    "    # If mask it True -> Constituent is INVALID.\n",
    "    # This is torch convention.\n",
    "    mask = X_pid == 0\n",
    "    \n",
    "    # Only fit a normalizer on training data, not on testing data.\n",
    "    # Reuse normalizer from training data for testing data.\n",
    "    if preprocessing_data is None:\n",
    "        # Fit normalizer on masked data.\n",
    "        normalizer = StandardScaler()\n",
    "        normalizer.fit(X_kinematics[~mask])\n",
    "\n",
    "        # Fit one-hot encoder on PID data.\n",
    "        one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        one_hot_encoder.fit(X_pid[~mask].reshape(-1, 1))\n",
    "\n",
    "        preprocessing_data = PreprocessingData(\n",
    "            normalizer=normalizer,\n",
    "            one_hot_encoder=one_hot_encoder\n",
    "        )\n",
    "\n",
    "    # Apply transformation to data.\n",
    "    X_kinematics = preprocessing_data.normalizer.transform(X_kinematics.reshape(-1, 4)).reshape(X_kinematics.shape)\n",
    "    X_pid = preprocessing_data.one_hot_encoder.transform(X_pid.reshape(-1, 1)).reshape(*X_pid.shape, -1)\n",
    "\n",
    "    # Construct final features\n",
    "    X = np.concatenate([X_kinematics, X_pid], axis=-1)\n",
    "    \n",
    "    # Mask out bad features using the mask we computed earlier.\n",
    "    X = np.where(mask[..., None], 0, X)\n",
    "\n",
    "    # Convert to torch tensor format.\n",
    "    X = torch.from_numpy(X).float()\n",
    "    y = torch.from_numpy(y).float()\n",
    "    mask = torch.from_numpy(mask)\n",
    "\n",
    "    dataset = TensorDataset(X, y, mask)\n",
    "\n",
    "    return dataset, preprocessing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create datasets.\n",
    "# Notice how we reuse the preprocessing data from the training data.\n",
    "train_dataset, preprocessing_data = preprocess_data(X_train, y_train)\n",
    "test_dataset, preprocessing_data = preprocess_data(X_test, y_test, preprocessing_data=preprocessing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab an example batch and examine its contents.\n",
    "# Batches consist of (X, y, mask) tuples.\n",
    "batch = test_dataset[:32]\n",
    "for i, element in enumerate(batch):\n",
    "    print(\"batch[{}].shape = {}\\n        .dtype = {}\".format(i, element.shape, element.dtype))\n",
    "\n",
    "num_features = batch[0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "Here we implement a basic attention mechanism on constituents.\n",
    "\n",
    "A couple of helper function are provided for working with padded arrays with a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A utility function we provide for you.\n",
    "# A masked verion of the softmax function so that the invalid elements are ignored and set to 0 at all times.\n",
    "def masked_softmax(similarities: Tensor, mask: Tensor, dim: int = -1) -> Tensor:\n",
    "    \"\"\"\n",
    "    Input Shapes\n",
    "    ------------\n",
    "    similarities: [B, N, N]\n",
    "    mask: [B, N]\n",
    "\n",
    "    Output Shape\n",
    "    ------------\n",
    "    masked_softmax_similarities: [B, N, N]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    B, N = mask.shape\n",
    "\n",
    "    # Attention mask will be where both the row and column are valid\n",
    "    square_mask = mask.reshape(B, N, 1) & mask.reshape(B, 1, N)\n",
    "\n",
    "    # Set masked logits to negative infinity.\n",
    "    # When performing softmax, these logits will become zero.\n",
    "    similarities = similarities.masked_fill(square_mask, float('-inf'))\n",
    "\n",
    "    # Perform softmax.\n",
    "    attention_weights = F.softmax(similarities, dim=dim)\n",
    "\n",
    "    # The masked rows will have invalid attention weights, convert them to zero for simplicity.\n",
    "    attention_weights = torch.nan_to_num(attention_weights, nan=0.0)\n",
    "\n",
    "    return attention_weights\n",
    "\n",
    "\n",
    "# A utility function we provide for you.\n",
    "# Mask out any vector to make sure any invalid entries are zero.\n",
    "def mask_vector(vector: Tensor, mask: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Input Shapes\n",
    "    ------------\n",
    "    vector: [B, N, D]\n",
    "    mask: [B, N]\n",
    "\n",
    "    Output Shape\n",
    "    ------------\n",
    "    masked_vector: [B, N, D]\n",
    "\n",
    "    \"\"\"\n",
    "    return vector.masked_fill(mask[..., None], 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Self-Attention\n",
    "\n",
    "First we implement the basic dot-product self-attention layer.\n",
    "We will not worry about multi-head attention for now.\n",
    "\n",
    "Your assignment will be to implement this attention mechanism following the formulas presented in the slides or attention is all you need paper. \\\n",
    "https://arxiv.org/pdf/1706.03762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, features: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.query = nn.Linear(features, features)\n",
    "        self.key = nn.Linear(features, features)\n",
    "        self.value = nn.Linear(features, features)\n",
    "\n",
    "    def forward(self, x: Tensor, src_key_padding_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Input shapes\n",
    "        ------------\n",
    "        x: [B, N, D]\n",
    "        mask: [B, N]\n",
    "\n",
    "        Output shapes\n",
    "        ------------\n",
    "        O: [B, N, D]\n",
    "        A: [B, N, N]\n",
    "        \"\"\"\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # Assignment 1.\n",
    "        # Implement the SelfAttention module.\n",
    "        # HINT: Torch can perform batch matrix multiplication using the @ operator.\n",
    "        #       A: [B, I, J]\n",
    "        #       B: [B, J, K]\n",
    "        #       C: [B, I, K]\n",
    "        #       C = A @ B \n",
    "        # ----------------------------------------------------\n",
    "\n",
    "        # Compute query, key, value.\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "\n",
    "        # Compute attention similarities.\n",
    "        S = (Q @ K.transpose(1, 2)) / np.sqrt(self.num_features)\n",
    "\n",
    "        # Compute attention weights\n",
    "        A = masked_softmax(S, src_key_padding_mask)\n",
    "\n",
    "        # Compute output.\n",
    "        O = A @ V\n",
    "\n",
    "        return O, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transformer Encoder Block\n",
    "\n",
    "Now we combine the self-attention block we implemented above with the other components of a transformer.\n",
    "\n",
    "This will form a basic building block that we can repeat over and over again.\n",
    "\n",
    "Implement the internal logic of the transformer encoder following the slides or the original paper. \\\n",
    "https://arxiv.org/pdf/1706.03762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Following the original paper, the feed forward part of the transformer uses two linear layers.\n",
    "# First we expand the dimensions, apply a non-linearlity, and then contract the dimensions back.\n",
    "class FeedForwardBlock(nn.Sequential):\n",
    "    def __init__(self, features: int, feed_forward_features: int):\n",
    "        super().__init__(\n",
    "            nn.Linear(features, feed_forward_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feed_forward_features, features)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, features: int, feed_forward_features: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = SelfAttention(features)\n",
    "        self.layer_norm1 = nn.LayerNorm(features)\n",
    "\n",
    "        self.feed_forward = FeedForwardBlock(features, feed_forward_features)\n",
    "        self.layer_norm2 = nn.LayerNorm(features)\n",
    "\n",
    "    def forward(self, x: Tensor, src_key_padding_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Input shapes\n",
    "        ------------\n",
    "        x: [B, N, D]\n",
    "        src_key_padding_mask: [B, N]\n",
    "\n",
    "        Output shapes\n",
    "        ------------\n",
    "        A: [B, N, N]\n",
    "        O: [B, N, D]\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Assignment 2.\n",
    "        # Implement the TransformerBlock module.\n",
    "\n",
    "        # NOTE: There are two version of the transformer. PRE-NORM and POST-NORM.\n",
    "        # The different is whether to apply the layer-norm before attention / feed-forward or after.\n",
    "        # Some interestin discussion on the difference: https://arxiv.org/pdf/2002.04745\n",
    "        # Both are good for this tutorial, but PRE-NORM is generally better in my experience.\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Transformer Block\n",
    "        y = self.layer_norm1(x)\n",
    "        y = self.attention(y, src_key_padding_mask)[0]\n",
    "        x = x + y\n",
    "        \n",
    "        # Feed Forward Block\n",
    "        y = self.layer_norm2(x)\n",
    "        y = self.feed_forward(y)\n",
    "        x = x + y\n",
    "\n",
    "        return mask_vector(x, src_key_padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jet Embedding\n",
    "\n",
    "Since this is a Set Classification problem, we will need some way to add an additional input / output responsible for summarizing the entire jet. \\\n",
    "This is very common in particle physics, as we typically want to summarize a set to extract an observable.\n",
    "\n",
    "This will consist of:\n",
    "\n",
    "1. Storing a learned vector to add as an extra input. Also make sure the mask is updated accordingly.\n",
    "2. Extracting the learned vector after processing to get a summary of all of the inputs.\n",
    "\n",
    "![Event Embedding](./EventEmbedding.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AddJetEmbedding(nn.Module):\n",
    "    def __init__(self, features: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.jet_embedding = nn.Parameter(torch.randn(1, 1, features))\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Input shapes\n",
    "        ------------\n",
    "        x: [B, N, D]\n",
    "        mask: [B, N]\n",
    "\n",
    "        Output shapes\n",
    "        ------------\n",
    "        x: [B, N + 1, D]\n",
    "        mask: [B, N + 1]\n",
    "        \n",
    "        \"\"\"\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Assignment 3.\n",
    "        # Implement the AddJetEmbedding module.\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        \n",
    "        B, N, D = x.shape\n",
    "\n",
    "        # Add the jet embedding to the input.\n",
    "        jet_embedding = self.jet_embedding.expand(B, 1, D)\n",
    "        x = torch.cat([jet_embedding, x], dim=1)\n",
    "\n",
    "        # Create a mask for the jet embedding.\n",
    "        jet_mask = torch.zeros(B, 1, dtype=mask.dtype, device=mask.device)\n",
    "        mask = torch.cat([jet_mask, mask], dim=1)\n",
    "\n",
    "        return x, mask\n",
    "    \n",
    "\n",
    "class ExtractJetEmbedding(nn.Module):\n",
    "    def forward(self, x: Tensor, mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Input shapes\n",
    "        ------------\n",
    "        x: [B, N, D]\n",
    "        mask: [B, N]\n",
    "\n",
    "        Output shapes\n",
    "        ------------\n",
    "        x: [B, D]\n",
    "        mask: [B]\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Assignment 3.\n",
    "        # Implement the ExtractJetEmbedding module.\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Extract the jet embedding from the input.\n",
    "        return x[:, 0], mask[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task\n",
    "\n",
    "Now we define the entire network for the quark / gluon set classification task. \\\n",
    "We combine the block we defined above with simple linear embedding and output layers to create a complete network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple Linear embedding layer.\n",
    "class Embedding(nn.Linear):\n",
    "    def __init__(self, input_features: int, hidden_features: int):\n",
    "        super().__init__(input_features, hidden_features)\n",
    "\n",
    "# Simple Linear output layer for binary classification.\n",
    "# This layer outputs logits!!!\n",
    "class ClassifierOutput(nn.Linear):\n",
    "    def __init__(self, input_features: int):\n",
    "        super().__init__(input_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_features: int, attention_features: int, feed_forward_features: int, num_transformer_layers: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = Embedding(input_features, attention_features)\n",
    "        self.add_jet_embedding = AddJetEmbedding(attention_features)\n",
    "\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerEncoder(attention_features, feed_forward_features) for _ in range(num_transformer_layers)\n",
    "        ])\n",
    "\n",
    "        # If you couldn't finish the previous assignments, you can use the nn.TransformerEncoderLayer instead.\n",
    "        # Also this would be the official torch version.\n",
    "        # You can play around with the number of heads, norm_first, etc. after the initial run through.\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        # self.transformer_layers = nn.ModuleList([\n",
    "        #     nn.TransformerEncoderLayer(\n",
    "        #         d_model=attention_features, \n",
    "        #         nhead=1, \n",
    "        #         dim_feedforward=feed_forward_features, \n",
    "        #         dropout=0.0, \n",
    "        #         batch_first=True, \n",
    "        #         norm_first=True\n",
    "        #     ) for _ in range(num_transformer_layers)\n",
    "        # ])\n",
    "\n",
    "        self.extract_jet_embedding = ExtractJetEmbedding()\n",
    "        self.output = ClassifierOutput(attention_features)\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Input shapes\n",
    "        ------------\n",
    "        x: [B, N, I]\n",
    "        mask: [B, N]\n",
    "\n",
    "        Output shapes\n",
    "        ------------\n",
    "        logits: [B]\n",
    "        \n",
    "        \"\"\"\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Assignment 4.\n",
    "        # Implement the TransformerClassifier module.\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Embedding Layer\n",
    "        x = self.embedding(x)\n",
    "        x = mask_vector(x, mask)\n",
    "\n",
    "        # Add Jet Embedding\n",
    "        x, mask = self.add_jet_embedding(x, mask)\n",
    "\n",
    "        # Transformer Layers\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x, src_key_padding_mask=mask)\n",
    "\n",
    "        # Extract Jet Embedding\n",
    "        x, mask = self.extract_jet_embedding(x, mask)\n",
    "        \n",
    "        # Output Layer\n",
    "        logits = self.output(x)\n",
    "        logits = logits.squeeze(-1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "A simple training loop on this example dataset.\n",
    "There are two networks to choose from, a larger and smaller network.\n",
    "\n",
    "The larger network is able to almost match the results of 1810.05165 without tuning. \\\n",
    "Further performance improvement can be had by fine-tuning the archtecture to the classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Big Network on GPU ~ 20 minutes to train\n",
    "# Small Network on GPU ~ 2 minutes to train\n",
    "\n",
    "USE_CUDA = True\n",
    "BIG_NETWORK = True\n",
    "\n",
    "if BIG_NETWORK:\n",
    "    ATTENTION_FEATURES = 128\n",
    "    FEED_FORWARD_FEATURES = 256\n",
    "    NUM_TRANSFORMER_LAYERS = 6\n",
    "    NUM_EPOCHS = 40\n",
    "\n",
    "else:\n",
    "    ATTENTION_FEATURES = 64\n",
    "    FEED_FORWARD_FEATURES = 128\n",
    "    NUM_TRANSFORMER_LAYERS = 4\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "network = TransformerClassifier(\n",
    "    input_features=num_features,\n",
    "    attention_features=ATTENTION_FEATURES,\n",
    "    feed_forward_features=FEED_FORWARD_FEATURES,\n",
    "    num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    network.parameters(), \n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "if USE_CUDA:\n",
    "    network = network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "with tqdm(range(NUM_EPOCHS), position=0, desc='Training Epoch') as epoch_progress_bar:\n",
    "    for epoch in epoch_progress_bar:\n",
    "        with tqdm(train_dataloader, position=1, leave=False, desc='Training Batch') as batch_progress_bar:\n",
    "            for batch in batch_progress_bar:\n",
    "                X, y, src_key_padding_mask = batch\n",
    "\n",
    "                if USE_CUDA:\n",
    "                    X = X.cuda()\n",
    "                    y = y.cuda()\n",
    "                    src_key_padding_mask = src_key_padding_mask.cuda()\n",
    "\n",
    "                logits = network(X, src_key_padding_mask)\n",
    "                loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_progress_bar.set_postfix_str(\"Loss: {:.4f}\".format(loss.item()))\n",
    "                losses.append(loss.item())\n",
    "\n",
    "if BIG_NETWORK:\n",
    "    torch.save(network.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(gaussian_filter1d(losses, sigma=100.0))\n",
    "plt.xlabel(\"Batch Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Skip to here if you dont want to wait\n",
    "if BIG_NETWORK:\n",
    "    network.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        X, y, src_key_padding_mask = batch\n",
    "\n",
    "        if USE_CUDA:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "            src_key_padding_mask = src_key_padding_mask.cuda()\n",
    "\n",
    "        logits = network(X, src_key_padding_mask)\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        test_predictions.append(probabilities.cpu().numpy())\n",
    "\n",
    "test_predictions = np.concatenate(test_predictions)\n",
    "\n",
    "print(metrics.classification_report(y_test, test_predictions > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y_test, test_predictions)\n",
    "plt.plot(fpr, tpr, label=\"AUC: {:.3f}\".format(metrics.roc_auc_score(y_test, test_predictions)))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Attention\n",
    "\n",
    "Add torch hooks to capture the attention weights from each attention layer.\n",
    "This will let us examine what the network is paying attention to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "def plot_attention(A):\n",
    "    num_constituents = A.shape[0]\n",
    "    \n",
    "    plt.imshow(A[::-1], cmap='viridis', aspect='auto')\n",
    "    plt.xlabel(\"Constituent\")\n",
    "    plt.ylabel(\"Constituent\")\n",
    "    plt.xticks(np.arange(num_constituents) - 0.5, [f\"\" for x in np.arange(num_constituents)])\n",
    "    plt.yticks(np.arange(num_constituents) - 0.5, [f\"\" for x in np.arange(num_constituents)])\n",
    "\n",
    "    plt.xticks(np.arange(num_constituents), [f\"{x}\" for x in np.arange(num_constituents)], minor=True)\n",
    "    plt.yticks(np.arange(num_constituents), [f\"{x}\" for x in np.arange(num_constituents)][::-1], minor=True)\n",
    "\n",
    "    plt.colorbar(label=\"Attention Weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attentions = []\n",
    "\n",
    "def attention_hook(module, input, output):\n",
    "    attentions.append(output[1])\n",
    "    return output\n",
    "\n",
    "hooks = []\n",
    "\n",
    "for name, module in network.named_modules():\n",
    "    if isinstance(module, (SelfAttention, nn.MultiheadAttention)):\n",
    "        hooks.append(module.register_forward_hook(attention_hook))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick an example jet and lets look at the attention weights for this jet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract an example jet.\n",
    "INDEX = 8\n",
    "\n",
    "x, y, mask = test_dataset[INDEX:INDEX  + 1]\n",
    "x = x.cuda()\n",
    "mask = mask.cuda()\n",
    "y = y.numpy()\n",
    "\n",
    "# Remove the padding jets since this is a one element batch.\n",
    "num_constituents = (~mask).sum().item()\n",
    "x = x[:, :num_constituents]\n",
    "mask = mask[:, :num_constituents]\n",
    "\n",
    "num_constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the network, keeping track of the attention weights for each transformer layer.\n",
    "with torch.no_grad():\n",
    "    attentions.clear()\n",
    "    network(x, mask)\n",
    "    attentions = [attention[0].cpu().numpy() for attention in attentions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot individual attention matrices for every layer and every input\n",
    "\n",
    "First we look at the individual attention weights for every layer, sequentially.\n",
    "\n",
    "These are the raw $A$ normalized similarity matrices we extracted during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, A in enumerate(attentions):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plot_attention(A)\n",
    "    plt.title(f\"Attention Matrix for Layer {i + 1}\")\n",
    "    plt.xticks(rotation=-90, minor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a combined attention matrix\n",
    "\n",
    "We can combine all of the attention matrices together by simply multiplying them together.\n",
    "\n",
    "If $A_i$ is the attention matrix for layer $i$, then the total attention is simply:\n",
    "$$\n",
    "A = \\prod_{i=1}^N A_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = np.eye(num_constituents + 1)\n",
    "for attention in attentions:\n",
    "    A = attention @ A\n",
    "\n",
    "plot_attention(A)\n",
    "plt.title(\"Total Attention Matrix\")\n",
    "plt.xticks(rotation=-90, minor=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus on the Jet Vector\n",
    "\n",
    "Since we are only performing a Jet-level classification of all of the constituents, all of the rows are actually the same.\n",
    "We can just look at the first vector's attention (the special jet vector) to get a better look at the importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.bar(np.arange(A.shape[0]), A[0])\n",
    "plt.xlabel(\"Constituent\")\n",
    "plt.ylabel(\"Attention Weight\")\n",
    "plt.title(\"Jet Vector Attention Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Classification Task\n",
    "\n",
    "As a challenge, lets say that we want to predict something about every element of a set.\n",
    "\n",
    "We will load in the SPANet dataset from here. https://github.com/Alexanders101/SPANet/blob/master/docs/TTBar.md\n",
    "\n",
    "- This dataset consists of a collection of jets. \n",
    "- Jets will be represented as collections of $(p_T, \\eta, \\phi, m)$ four-momentum vectors.\n",
    "- Targets will be the parton labels originating from a full-hadronic $t \\bar{t}$ decay.\n",
    "- We will also limit the dataset to only events where all 6 partons are assigned to a jet.\n",
    "\n",
    "We will not implement the full SPANet algorithm here. We focus on a more basic element-wise approach as an example. This has key limitations:\n",
    "1. This approach will not know about or take into account how many of each parton should exist.\n",
    "2. This approach will know nothing about symmetry or symmetric assignments.\n",
    "\n",
    "This will serve as an introduction to using attention for set-wise classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"/global/cfs/cdirs/ntrain1/attention/full_hadronic_ttbar/training.h5\"\n",
    "TRAIN_SIZE = 10_000_000\n",
    "\n",
    "TEST_FILE = \"/global/cfs/cdirs/ntrain1/attention/full_hadronic_ttbar/testing.h5\"\n",
    "TEST_SIZE = 1_000_000\n",
    "\n",
    "def load_dataset(filepath, size):\n",
    "    with h5py.File(filepath, 'r') as file:\n",
    "        # Extract jet kinematics\n",
    "        x = np.stack((\n",
    "            file[\"INPUTS\"][\"Source\"][\"pt\"][:size],\n",
    "            file[\"INPUTS\"][\"Source\"][\"eta\"][:size],\n",
    "            file[\"INPUTS\"][\"Source\"][\"phi\"][:size],\n",
    "            file[\"INPUTS\"][\"Source\"][\"mass\"][:size]\n",
    "        ), axis=-1)\n",
    "\n",
    "        mask = ~file[\"INPUTS\"][\"Source\"][\"MASK\"][:size]\n",
    "        \n",
    "        # Assign per-jet labels\n",
    "        # Also keep track of how many parton are even reconstructable.\n",
    "        # For this example we only want to focus on events with all 6 partons assigned to jets.\n",
    "        y = np.zeros((x.shape[0], x.shape[1]), dtype=np.int64)\n",
    "\n",
    "        dummy_index = np.arange(x.shape[0])\n",
    "        num_targets = np.zeros(x.shape[0], dtype=np.int64)\n",
    "\n",
    "        y[dummy_index, file[\"TARGETS\"][\"t1\"][\"b\"][:size]] = 1\n",
    "        num_targets += file[\"TARGETS\"][\"t1\"][\"b\"][:size] >= 0\n",
    "\n",
    "        y[dummy_index, file[\"TARGETS\"][\"t1\"][\"q1\"][:size]] = 2\n",
    "        num_targets += file[\"TARGETS\"][\"t1\"][\"q1\"][:size] >= 0\n",
    "\n",
    "        y[dummy_index, file[\"TARGETS\"][\"t1\"][\"q2\"][:size]] = 3\n",
    "        num_targets += file[\"TARGETS\"][\"t1\"][\"q2\"][:size] >= 0\n",
    "\n",
    "        y[dummy_index, file[\"TARGETS\"][\"t2\"][\"b\"][:size]] = 4\n",
    "        num_targets += file[\"TARGETS\"][\"t2\"][\"b\"][:size] >= 0\n",
    "\n",
    "        y[dummy_index, file[\"TARGETS\"][\"t2\"][\"q1\"][:size]] = 5\n",
    "        num_targets += file[\"TARGETS\"][\"t2\"][\"q1\"][:size] >= 0\n",
    "\n",
    "        y[dummy_index, file[\"TARGETS\"][\"t2\"][\"q2\"][:size]] = 6\n",
    "        num_targets += file[\"TARGETS\"][\"t2\"][\"q2\"][:size] >= 0\n",
    "\n",
    "        y = np.where(mask, 0, y)\n",
    "\n",
    "    # Hardcoded normalization from training dataset for simplicity\n",
    "    x = x - np.array([6.9162e+01, 0, 0,  8.3870e+00])\n",
    "    x = x / np.array([50.5310,  1.4054,  1.8138,  6.5079])\n",
    "\n",
    "    # Full Events only\n",
    "    x = x[num_targets == 6]\n",
    "    y = y[num_targets == 6]\n",
    "    mask = mask[num_targets == 6]\n",
    "\n",
    "    # Convert to torch\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).long()\n",
    "    mask = torch.from_numpy(mask).bool()\n",
    "\n",
    "    return TensorDataset(x, y, mask)\n",
    "\n",
    "train_dataset = load_dataset(TRAIN_FILE, TRAIN_SIZE)\n",
    "test_dataset = load_dataset(TEST_FILE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple Linear multi-output layer for multi-class classification.\n",
    "# This layer outputs logits!!!\n",
    "class MultiClassifierOutput(nn.Linear):\n",
    "    def __init__(self, input_features: int, num_classes: int):\n",
    "        super().__init__(input_features, num_classes)\n",
    "\n",
    "class RemoveEventEmbedding(nn.Module):\n",
    "    def forward(self, x, mask):\n",
    "        return x[:, 1:], mask[:, 1:]\n",
    "\n",
    "class TransformerMultiClassifier(nn.Module):\n",
    "    def __init__(self, input_features: int, num_classes: int, attention_features: int, feed_forward_features: int, num_transformer_layers: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = Embedding(input_features, attention_features)\n",
    "        self.add_event_embedding = AddJetEmbedding(attention_features)\n",
    "\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerEncoder(attention_features, feed_forward_features) for _ in range(num_transformer_layers)\n",
    "        ])\n",
    "\n",
    "        self.remove_event_embedding = RemoveEventEmbedding()\n",
    "        self.output = MultiClassifierOutput(attention_features, num_classes)\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Input shapes\n",
    "        ------------\n",
    "        x: [B, N, I]\n",
    "        mask: [B, N]\n",
    "\n",
    "        Output shapes\n",
    "        ------------\n",
    "        logits: [B, N]\n",
    "        \n",
    "        \"\"\"\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Assignment 6.\n",
    "        # Implement the TransformerMultiClassifier module.\n",
    "        # \n",
    "        # You may optionally also use an event summary vector in this network as well.\n",
    "        # Although we dont use the event vector for classification, there has been work \n",
    "        # showing that the extra vector allows the network to learn contextual information\n",
    "        # related to all objects.\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Embedding Layer\n",
    "        x = self.embedding(x)\n",
    "        x = mask_vector(x, mask)\n",
    "\n",
    "        x, mask = self.add_event_embedding(x, mask)\n",
    "\n",
    "        # Transformer Layers\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x, src_key_padding_mask=mask)\n",
    "        \n",
    "        # Output Layer\n",
    "        x, mask = self.remove_event_embedding(x, mask)\n",
    "        logits = self.output(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Small Network on GPU ~ 20 minutes to train\n",
    "\n",
    "USE_CUDA = True\n",
    "\n",
    "ATTENTION_FEATURES = 64\n",
    "FEED_FORWARD_FEATURES = 128\n",
    "NUM_TRANSFORMER_LAYERS = 6\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# This time only feeding in kinematics (pt, y, sin(phi), cos(phi)\n",
    "# Outputting the PID as a classification task.\n",
    "network = TransformerMultiClassifier(\n",
    "    input_features=4,\n",
    "    num_classes=7,\n",
    "    attention_features=ATTENTION_FEATURES,\n",
    "    feed_forward_features=FEED_FORWARD_FEATURES,\n",
    "    num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    network.parameters(), \n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "if USE_CUDA:\n",
    "    network = network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "with tqdm(range(NUM_EPOCHS), position=0, desc='Training Epoch') as epoch_progress_bar:\n",
    "    for epoch in epoch_progress_bar:\n",
    "        with tqdm(train_dataloader, position=1, leave=False, desc='Training Batch') as batch_progress_bar:\n",
    "            for batch in batch_progress_bar:\n",
    "                X, y, src_key_padding_mask = batch\n",
    "\n",
    "                if USE_CUDA:\n",
    "                    X = X.cuda()\n",
    "                    y = y.cuda()\n",
    "                    src_key_padding_mask = src_key_padding_mask.cuda()\n",
    "\n",
    "                # Ask the network for pid logits\n",
    "                logits = network(X, src_key_padding_mask)\n",
    "\n",
    "                # Only compute the loss for valid constituents.\n",
    "                masked_logits = logits[~src_key_padding_mask]\n",
    "                masked_targets = y[~src_key_padding_mask]\n",
    "                loss = F.cross_entropy(masked_logits, masked_targets)\n",
    "\n",
    "                # Perform backpropagation.\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_progress_bar.set_postfix_str(\"Loss: {:.4f}\".format(loss.item()))\n",
    "                losses.append(loss.item())\n",
    "\n",
    "torch.save(network.state_dict(), 'multi_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(gaussian_filter1d(losses, sigma=100.0))\n",
    "plt.xlabel(\"Batch Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Skip to here if you dont want to wait\n",
    "network.load_state_dict(torch.load('multi_checkpoint.pth'))\n",
    "\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        X, y, src_key_padding_mask = batch\n",
    "\n",
    "        if USE_CUDA:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "            src_key_padding_mask = src_key_padding_mask.cuda()\n",
    "\n",
    "        # Ask the network for pid logits\n",
    "        logits = network(X, src_key_padding_mask)\n",
    "\n",
    "        # Only compute the loss for valid constituents.\n",
    "        masked_logits = logits[~src_key_padding_mask]\n",
    "        masked_targets = y[~src_key_padding_mask]\n",
    "\n",
    "        masked_probabilities = F.softmax(masked_logits, dim=-1)\n",
    "        test_predictions.append(masked_probabilities.cpu().numpy())\n",
    "        test_targets.append(masked_targets.cpu().numpy())\n",
    "\n",
    "test_predictions = np.concatenate(test_predictions)\n",
    "test_targets = np.concatenate(test_targets)\n",
    "\n",
    "print(metrics.classification_report(test_targets, test_predictions.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attentions = []\n",
    "\n",
    "def attention_hook(module, input, output):\n",
    "    attentions.append(output[1])\n",
    "    return output\n",
    "\n",
    "hooks = []\n",
    "\n",
    "for name, module in network.named_modules():\n",
    "    if isinstance(module, (SelfAttention, nn.MultiheadAttention)):\n",
    "        hooks.append(module.register_forward_hook(attention_hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract an example jet.\n",
    "INDEX = 2\n",
    "\n",
    "x, y, mask = test_dataset[INDEX:INDEX  + 1]\n",
    "x = x.cuda()\n",
    "mask = mask.cuda()\n",
    "y = y.numpy()\n",
    "\n",
    "# Remove the padding jets since this is a one element batch.\n",
    "num_vectors = (~mask).sum().item()\n",
    "x = x[:, :num_vectors]\n",
    "mask = mask[:, :num_vectors]\n",
    "\n",
    "y = y[0, :num_vectors]\n",
    "\n",
    "# Run the network, keeping track of the attention weights for each transformer layer.\n",
    "with torch.no_grad():\n",
    "    attentions.clear()\n",
    "\n",
    "    # Split the data into kinematics and PID.\n",
    "    p = network(x, mask)[0].cpu().numpy()\n",
    "    attentions = [attention[0].cpu().numpy() for attention in attentions]\n",
    "    \n",
    "print(\"True      : \", y)\n",
    "print(\"Predicted : \", p.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PARTON_NAMES = [\"$\\\\emptyset$\", \"$b_1$\", \"$q_1$\", \"$q_1$\", \"$b_2$\", \"$q_2$\", \"$q_2$\"]\n",
    "\n",
    "for i, A in enumerate(attentions):\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "    plot_attention(A)\n",
    "    plt.title(f\"Attention Matrix for Layer {i + 1}\")\n",
    "    \n",
    "    has_extra_event_vector = A.shape[0] > num_vectors\n",
    "    if has_extra_event_vector:\n",
    "        ax.set_yticklabels(([\"E\"] + [PARTON_NAMES[int(x)] for x in y])[::-1], minor=True)\n",
    "        ax.set_xticklabels([\"E\"] + [PARTON_NAMES[int(x)] for x in y], minor=True)\n",
    "    else:\n",
    "        ax.set_yticklabels([PARTON_NAMES[int(x)] for x in y][::-1], minor=True)\n",
    "        ax.set_xticklabels([PARTON_NAMES[int(x)] for x in y], minor=True)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPANet\n",
    "\n",
    "The previous network showed a simple solution to the jet-parton assignment problem. It didn't perform very well because it didn't take into account symmetries.\n",
    "\n",
    "If you're ready to try out the full symmetric attention network, you can follow the guide here: https://github.com/Alexanders101/SPANet/blob/master/docs/TTBar.md\n",
    "\n",
    "\n",
    "\n",
    "1. Open a terminal window in jupyterlab.\n",
    "2. Run `source setup_spanet.sh` to clone and load environment.\n",
    "3. Follow the guide as normal. Ignore the first two section setting up environment and getting the data. All of that is done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.3.1",
   "language": "python",
   "name": "pytorch-2.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
